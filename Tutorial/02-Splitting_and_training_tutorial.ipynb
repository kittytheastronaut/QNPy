{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d4a32f9",
   "metadata": {},
   "source": [
    "# Splitting and training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568476de",
   "metadata": {},
   "source": [
    "Before running this script, you must create the following folders in the directory where your Python notebook is located:\n",
    "1. ./dataset/train -- folder for saving data for traing after splitting your original dataset\n",
    "2. ./dataset/test -- folder for test data \n",
    "3. ./dataset/val -- folder for validation data\n",
    "4. ./output/cnp_model.pth -- folder where you are going to save your trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83322b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import QNPy #Importing the package\n",
    "from QNPy import SPLITTING_AND_TRAINING as st #Importing SPLITTING_AND_TRAINING module from the package\n",
    "from QNPy.SPLITTING_AND_TRAINING import * #Importing all packages from SPLITTING_AND_TRAINING module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc36e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_SRC = \"./preproc\" #Path to transformed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0fcc559",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir(DATA_SRC) #listing the transformed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eaa67ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#path to TRAIN, TEST and VAL folders where your splitted data will be saved. \n",
    "#You can directly enter this informations in split_data function\n",
    "TRAIN_FOLDER = './dataset/train/'\n",
    "TEST_FOLDER = './dataset/test/'\n",
    "VAL_FOLDER = './dataset/val/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce436a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#running the function for splitting the data\n",
    "st.split_data(files, DATA_SRC, TRAIN_FOLDER, TEST_FOLDER, VAL_FOLDER) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc877ae4",
   "metadata": {},
   "source": [
    "# TRAINING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce784a5",
   "metadata": {},
   "source": [
    "# Special note for mac os users: \n",
    "\n",
    "When creating folders with mac operating systems, hidden .DS_Store files may be created. The user must delete these files before starting training from each folder. The best way is to go into each folder individually and run the command:\n",
    "\n",
    "!rm -f .DS_Store\n",
    "\n",
    "Important note: Deleting files using the \"delete\" directly in the folders does not remove hidden files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097d1a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH_TRAIN = \"./dataset/train\" #path to train folder\n",
    "DATA_PATH_VAL = \"./dataset/val\" #path to val folder\n",
    "\n",
    "MODEL_PATH = \"./output/cnp_model.pth\" #path for saving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9780754c",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=32 #Defining the batch size, it should remain 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7e3e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#running the function for getting the data loaders of data that are going to be trained\n",
    "trainLoader, valLoader = st.get_data_loaders(DATA_PATH_TRAIN, DATA_PATH_VAL, BATCH_SIZE) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d3a931",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining the device for testing, it can be CPU of CUDA\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad2e48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#runing the function fo creating the model (deterministic model is default) \n",
    "#and optimiser (LogProbLoss), mseMetric (MSELoss)\n",
    "model, optimizer, criterion, mseMetric, maeMetric = st.create_model_and_optimizer(device) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d45da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for training the data\n",
    "# numbers that we give in this example are: \n",
    "#1 - number of training runs\n",
    "#3000 - number of epochs\n",
    "#2000 - number of early stopping limit\n",
    "# These numbers are optional and can be changed as needed.\n",
    "history_loss_train, history_loss_val, \\\n",
    "history_mse_train, history_mse_val, \\\n",
    "history_mae_train, history_mae_val, \\\n",
    "epoch_counter_train_loss, epoch_counter_train_mse, \\\n",
    "epoch_counter_train_mae, epoch_counter_val_loss, \\\n",
    "epoch_counter_val_mse, epoch_counter_val_mae = st.train_model(\n",
    "    model, trainLoader, valLoader, criterion, optimizer, 1, 3000, 2000, mseMetric, maeMetric, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2407ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the file names for saving the lists for all histories\n",
    "file_names = [\"history_loss_train.csv\", \"history_loss_val.csv\", \"history_mse_train.csv\", \"history_mse_val.csv\",\n",
    "              \"history_mae_train.csv\", \"history_mae_val.csv\", \"epoch_counter_train_loss.csv\",\n",
    "              \"epoch_counter_train_mse.csv\", \"epoch_counter_train_mae.csv\", \"epoch_counter_val_loss.csv\",\n",
    "              \"epoch_counter_val_mse.csv\", \"epoch_counter_val_mae.csv\"]\n",
    "\n",
    "# Define the lists\n",
    "lists = [history_loss_train, history_loss_val, history_mse_train, history_mse_val, history_mae_train,\n",
    "         history_mae_val, epoch_counter_train_loss, epoch_counter_train_mse, epoch_counter_train_mae,\n",
    "         epoch_counter_val_loss, epoch_counter_val_mse, epoch_counter_val_mae]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b1bd69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#running the function for saving all lists with histories\n",
    "save_list= st.save_lists_to_csv(file_names, lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da500045",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace with the path to your history_loss_train CSV file\n",
    "history_loss_train_file = './history_loss_train.csv'  \n",
    "# Replace with the path to your history_loss_val CSV file\n",
    "history_loss_val_file = './history_loss_val.csv'  \n",
    "# Replace with the path to your epoch_counter_train_loss CSV file\n",
    "epoch_counter_train_loss_file = './epoch_counter_train_loss.csv'  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9e0c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting the Logprobloss after training\n",
    "logprobloss=st.plot_loss(history_loss_train_file, history_loss_val_file, epoch_counter_train_loss_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bdb05ea",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Replace with the path to your history_mse_train CSV file\n",
    "history_mse_train_file = './history_mse_train.csv'\n",
    "# Replace with the path to your history_mse_val CSV file\n",
    "history_mse_val_file = './history_mse_val.csv'  \n",
    "# Replace with the path to your epoch_counter_train_mse CSV file\n",
    "epoch_counter_train_mse_file = './epoch_counter_train_mse.csv'  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8161cf2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting the MSE metric after training\n",
    "msemetric=st.plot_mse(history_mse_train_file, history_mse_val_file, epoch_counter_train_mse_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed16428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace with the path to your history_mae_train CSV file\n",
    "history_mae_train_file = './history_mae_train.csv'\n",
    "# Replace with the path to your history_mae_val CSV file\n",
    "history_mae_val_file = './history_mae_val.csv'  \n",
    "# Replace with the path to your epoch_counter_train_mae CSV file\n",
    "epoch_counter_train_mae_file = './epoch_counter_train_mae.csv'  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b1ae01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting the MAE metric after training\n",
    "maemetric=st.plot_mae(history_mae_train_file, history_mae_val_file, epoch_counter_train_mae_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252bf6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "save=st.save_model(model, MODEL_PATH)#saving the trained model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
